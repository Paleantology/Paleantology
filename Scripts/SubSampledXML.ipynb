{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in the parsing notebook, we're going to prepare data from three sources (molecular, morphological and fossils without data, used only for their age information) for use with the BEAST2 suite of tools for divergence dating using the Fossilized Birth-Death model. This time around, we're going to subsample the fossil data - including every fossil, especially when they all have missing data, can make it really hard for the MCMC to converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dendropy\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do is load our the two libraries we'll be using: Pandas, a data-crunching library and Dendropy, a perennially excellent package for phylogenetic tree and dataset manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we parsed all the data into dataframes with extra info, such as higher taxonomy and ages. We're going to load that data now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morphTable = pd.read_csv(\"../Data/Morph/morphTNRS.csv\")\n",
    "molTable = pd.read_csv(\"new_df.csv\")\n",
    "fossTable = pd.read_csv(\"../Data/Morph/FossilTNRS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to subsample the fossils, we're first going to break them down by subfamily. We will then subsample within each subfamily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "families = fossTable.groupby('subfamily')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above defines some probability that a fossil will be included in the final set of fossils. I set this so that about 20% of the fossils would be included. This will still be a lot of fossils! Then, below, I put this into a dataframe so that I can merge my subset of fossils with my molecular and morphological data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-36d340b97ec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'specimen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'subfamily'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "samp = pd.DataFrame(molTable, columns=['specimen', 'subfamily'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'samp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fa06f6bf1257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmolMerge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'specimen'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subfamily'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmolMerge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fossil'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'No'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msamp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fossil'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Yes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmega_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmolMerge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmorphMerge\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmega_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmega_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'specimen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'samp' is not defined"
     ]
    }
   ],
   "source": [
    "morphMerge = morphTable[['Specimen', 'SubFamily']]\n",
    "morphMerge.columns = ['specimen','subfamily'] \n",
    "morphMerge['Fossil'] = 'No'\n",
    "molMerge = molTable[['specimen', 'subfamily']]\n",
    "molMerge.columns = ['specimen','subfamily']  \n",
    "molMerge['Fossil'] = 'No'\n",
    "samp['Fossil'] = 'Yes'\n",
    "mega_df = pd.concat([samp,molMerge,morphMerge]) \n",
    "mega_df = mega_df.drop_duplicates('specimen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load in DNA and character matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "molDat = dendropy.DnaCharacterMatrix.get_from_path(\"../Data/Mol/FINAL_666Trimmed.nex\", schema=\"nexus\",preserve_underscores=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = []\n",
    "samp_prop = .9\n",
    "\n",
    "for name, group in families:\n",
    "    for ind in group.specimen:\n",
    "        ind_val = random.random(1)\n",
    "        if ind_val > samp_prop:\n",
    "            sample.append([ind, name])\n",
    "sample = pd.DataFrame(sample)\n",
    "sample.columns = ['Specimen', 'subfamily']\n",
    "sample['Fossil'] = 'Yes'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morphDat = dendropy.StandardCharacterMatrix.get_from_path(\"../Data/Morph/KellerMatrix.nex\", schema=\"nexus\", preserve_underscores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for taxon in morphDat.taxon_namespace:\n",
    "    if taxon not in molDat.taxon_namespace:\n",
    "        molDat.taxon_namespace.add_taxon(str(taxon))\n",
    "print(molDat.taxon_namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morphDat = dendropy.StandardCharacterMatrix.get_from_path(\"../Data/Morph/KellerMatrix.nex\", schema=\"nexus\", preserve_underscores=True, taxon_namespace=molDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we create matrices of missing data for the fossils we're using for their age info - remeber that all taxa must be present in all data partitions in BEAST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names=[]\n",
    "names = sample.Specimen.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "md_val = \"?\"*139\n",
    "dict_of_dat = {}\n",
    "print(len(names))\n",
    "names = [name for name in names if name not in molDat.taxon_namespace]\n",
    "print(len(names))\n",
    "names_x = [name+'_X' for name in names]\n",
    "for name in names_x:                                                                                             \n",
    "\tdict_of_dat[name] = md_val\n",
    "dict_of_moldat = {}\n",
    "md_val = \"?\"*7099\n",
    "for name in names_x:                                                                                             \n",
    "\tdict_of_moldat[name] = md_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure that the names of the fossils are entered into the namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'lower_cased_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bdf0fdd0d17d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfossDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdendropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardCharacterMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_of_dat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtaxon_namespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmolDat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaxon_namespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfossmolDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdendropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDnaCharacterMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_of_moldat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaxon_namespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmolDat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaxon_namespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/dendropy/datamodel/charmatrixmodel.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, source_dict, char_matrix, case_sensitive_taxon_labels, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtextprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_str_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 taxon = char_matrix.taxon_namespace.require_taxon(key,\n\u001b[0;32m--> 751\u001b[0;31m                         is_case_sensitive=case_sensitive_taxon_labels)\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mtaxon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/dendropy/datamodel/taxonmodel.py\u001b[0m in \u001b[0;36mrequire_taxon\u001b[0;34m(self, label, is_case_sensitive)\u001b[0m\n\u001b[1;32m   1227\u001b[0m                 \u001b[0mis_case_sensitive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_case_sensitive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0mfirst_match_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m                 \u001b[0merror_if_not_found\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m                 )\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtaxon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/dendropy/datamodel/taxonmodel.py\u001b[0m in \u001b[0;36m_lookup_label\u001b[0;34m(self, label, is_case_sensitive, first_match_only, error_if_not_found)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtaxon\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_taxa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtaxon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_cased_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfirst_match_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mtaxon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'lower_cased_label'"
     ]
    }
   ],
   "source": [
    "fossDat = dendropy.StandardCharacterMatrix.from_dict(dict_of_dat,taxon_namespace=molDat.taxon_namespace) \n",
    "fossmolDat = dendropy.DnaCharacterMatrix.from_dict(dict_of_moldat, taxon_namespace=molDat.taxon_namespace)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if there are any morphology taxa that don't have molecular data, or vice versa, we pad that out now as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fossDat.replace_sequences(morphDat)\n",
    "morphDat.pack()\n",
    "#fossmolDat.replace_sequences(molDat)\n",
    "molDat.pack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we write the data out. Pack() fills the data with None values. These can be replaced by regex. Once you have done this, BEAST should happily read the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morphDat.write_to_path('samp_morphTest.nex', schema='nexus')\n",
    "molDat.write_to_path('samp_molTest.nex', schema='nexus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next bits, I'm going to show some parsing that will be useful if you want to use fossil tip ranges, such as in [this](http://sysbio.oxfordjournals.org/content/early/2016/07/27/sysbio.syw060.abstract) paper. In order to access the age information stored in my fossil data, I'm going to do merge between my fossil subsample, and my fossil database. This will allow me to pare down my fossil database to just the fossils I actually want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fossTNRS = pd.read_csv('../Data/Morph/FossilTNRS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fossTNRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at any of the XML files for the paper I linked to in the previous text, you'll see taxon names and ages are stored together in an XML block. Below, we assemble this XML block for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "namesdb = fossTNRS[fossTNRS['specimen'].isin(names)]\n",
    "nl = namesdb['specimen'].tolist()\n",
    "nm = namesdb['min_ma'].tolist()\n",
    "\n",
    "new_names = [name+'_X='+str(time) for name, time in zip(nl, nm)]\n",
    "new_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the XMLs, you might also notice that we can sample the tip ages, if we have an age range for a fossil. Below, I make the part of the XML block that varies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_taxon =  ['<taxon idref=\"'+name+'_X \" spec=\"Taxon\"/>' for name in names] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xml_taxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 1\n",
    "nl = namesdb['specimen'].tolist()\n",
    "nm = namesdb['min_ma'].tolist()\n",
    "nma = namesdb['max_ma'].tolist()\n",
    "\n",
    "for name, mi, ma in zip(nl, nm, nma):\n",
    "    print('<samplingDates id=\"samplingDate%d\" spec=\"beast.evolution.tree.SamplingDate\" taxon=\"@'  % count +name+'_X\" lower=\"'+str(mi)+'\" upper=\"'+str(ma)+'\"/>')\n",
    "    count=count+1\n",
    "\n",
    "    \n",
    "    #sample_taxon =  ['<samplingDates id=\"samplingDate%d\" spec=\"beast.evolution.tree.SamplingDate\" taxon=\"@'+name+'\" lower=\"'+str(mi)+'\" upper=\"'+str(ma)+'\"/>' for name,mi,ma in zip(names, merged.min_ma, merged.max_ma) %count count=count+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subsample tips involves some amount of manual assembly of XML. You can plug and chug this by copying the XML structure from the XML files associated with the paper. Below, I take the dataframe of all the taxa in our analysis and use it to constrain monophyloetic groups at the subfamily level. You can also create these in BEAUTi, but I really hate clicking things in a GUI, so i'm doing it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_names = [name+'_X' for name in nl]\n",
    "\n",
    "namesdb['specimen'] = x_names\n",
    "total = namesdb.append([molMerge, morphMerge])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "families = total.groupby('subfamily')\n",
    "for name, group in families:\n",
    "    print('<distribution id=\"'+name+'.prior\" spec=\"beast.math.distributions.MRCAPrior\" monophyletic=\"true\" tree=\"@Tree.t:samp_morphTest\">')\n",
    "    print('<taxonset id=\"'+name+'\" spec=\"TaxonSet\">')\n",
    "    for ind in set(group.specimen):\n",
    "        print('<taxon id=\"'+ind+'\" spec=\"Taxon\"/>')\n",
    "    print('</taxonset>'+'\\n'+'</distribution>')  \n",
    "            \n",
    "#    fname = name\n",
    "#   group.specimen.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm interested in looking at the posterior distribution of ages for all the ant clades, so I want to add those to the operators so that information gets written to the log. The below formats the ops block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, group in families:\n",
    "    print(' <log idref=\"'+name+'.prior\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I'm wrapping up this post, I am realizing I ought to do a schematic of the BEAST XML file to make it easier to understand the chunks of it if you're not an XML whiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, group in families:\n",
    "    for ind in group.specimen:\n",
    "        if ind in names or molDat.taxon_namespace:\n",
    "            print('yes')\n",
    "        else:\n",
    "            print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in molDat.taxon_namespace:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
